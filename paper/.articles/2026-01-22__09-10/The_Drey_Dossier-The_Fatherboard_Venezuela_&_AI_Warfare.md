# The Fatherboard: Venezuela & AI Warfare

I came across an [article](https://www.wearethemighty.com/military-news/venezuela-air-defense-deleted/) the other day titled *“How the US Deleted Venezuela’s Air Defenses So Quickly.”*

The piece essentially described what happened at 4 a.m. Eastern on January 3rd, when the U.S. Navy dismantled Venezuela’s entire air defense system in twenty minutes. For a decade, defense analysts had been warning about Venezuela’s Russian-made S-300 system, calling it the “Russian Shield,” a mobile beast capable of shooting down cruise missiles from 150 miles away, the kind of hardware that was supposed to sink American warships before they could even get close.

Here’s how it actually went down: The Navy jammed Venezuela’s radars with so much electronic noise that operators couldn’t see anything, forcing them to crank up their power just to pierce through the static. The moment they did, those radars lit up like beacons, and U.S. Anti-Radiation Missiles locked onto the signal and followed it home. Meanwhile, Tomahawks came in low, using Venezuela’s own mountains to hide from detection until it was too late. Twenty minutes, and the system that was supposed to be unstoppable didn’t fire a single shot.

But it was the title that stuck with me. That word: *deleted.*

Not destroyed, not neutralized, not taken offline. Deleted. That’s what you do to your browser history, to an embarrassing photo, to a text message you can’t bring yourself to send. It’s language from our world, not from war, and that choice tells you everything about where the real battlefield has moved. This isn’t just about blowing up hardware anymore; it’s about information, about what’s real and what isn’t, about making things vanish so completely it’s like they were never there at all.

I’m calling this system the Fatherboard, and Venezuela is where they built it, tested it, and flipped the switch.

## **Phase One: Building the Human Circuit**

In 2016, oil prices crashed and Venezuela’s economy collapsed overnight. Then Washington piled on sanctions, cutting Caracas off from U.S. financial markets, blocking the state oil company from getting paid, freezing billions in assets, and choking off critical imports. By 2018, annual inflation hit over 1,000,000 percent, with the monthly minimum wage dropping to about $30. Engineers, teachers, and nurses with advanced degrees couldn’t afford a week’s groceries on their formal salaries.

So what happens when you create mass desperation in a country full of educated people who suddenly can’t afford to eat? Someone shows up to harvest it.

Enter the ghost work platforms: Scale AI, Appen, Remotasks, Toloka. Cheerful interfaces promising to help people “earn in your spare time,” sitting on top of contracts with OpenAI, Microsoft, Meta, and Google. The AI systems being built by the richest companies on the planet need hundreds of millions of tiny human decisions to function, and someone has to provide them. Someone has to label images so algorithms learn what a stop sign looks like, tag videos so AI can recognize faces and weapons, sort text so machine learning models understand what counts as “hate” or “terrorism.”

By mid-2018, around 200,000 Venezuelans had signed up for this work at rates between 50 cents and $2 an hour. In a collapsed economy, that was ten times the minimum wage, which made it survival, not choice.

A teacher named Oskarina Fuentes left Venezuela for Colombia because she couldn’t feed her kids. Now she spends her nights labeling images—give the box a tick if this is a car, draw a rectangle around the person crossing the street, choose which comment is more “toxic.” Half a dollar an hour to teach AI owned by American companies how to see the world.

[![](https://substackcdn.com/image/fetch/$s_!t5iC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe74a895c-7008-4e90-a2cf-1cf0920fb547_317x454.webp)](https://substackcdn.com/image/fetch/$s_!t5iC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe74a895c-7008-4e90-a2cf-1cf0920fb547_317x454.webp)

In 2019, Scale AI rolled out Spanish-language recruitment ads and launched “Remotasks Plus,” pitched as a way to help Venezuelans “get through the crisis.” Workers described delayed payments, platforms that crashed and then punished them for incomplete jobs, and zero labor protections. In industry reports, Venezuelans became known as some of the lowest-paid data workers on earth, not because they lacked skills, but because they had no leverage.

This is the first circuit of the Fatherboard: economic collapse creates an educated but desperate labor pool, platforms harvest that pool at starvation wages, and the labor gets sold upstream to train AI systems that will power everything else.

---

This Substack is reader-supported. If you find this work valuable, consider subscribing to The Rough Riders tier

---

## **Phase Two: Wiring the Physical Circuit**

In July 2024, the Department of Defense awarded Scale AI roughly $199 million as part of a $708 million contract for AI and machine-learning data services. Scale AI (owned by Meta Platforms) is an American data annotation company; meaning it provides data labeling, model evaluation, and software to develop applications. A year later, the Pentagon unveiled GenAI.mil, a system piping models from Google, OpenAI, Anthropic, and Elon Musk’s xAI directly into military networks, with each company receiving around $200 million to adapt their models for intelligence triage, operational planning, and targeting. The defense secretary called AI “America’s next Manifest Destiny.”

In September 2025, Scale AI received another $100 million to deploy its platform across top-secret military networks. The CEO described it plainly: “We are moving AI out of the lab and into the hands of operators.”

Translation: All that cheap annotation work, all those images labeled by desperate people in collapsing economies, is now baked into systems that help the U.S. military decide what gets blown up, when, and how. The model that learned to distinguish a jacket from a shirt gets re-tuned to tell a civilian pickup from a military technical. The pattern recognition that optimized your Amazon cart now optimizes target selection. The image labeling that helped self-driving cars stay between the lines now helps targeting software identify radar installations from 40,000 feet.

The 50-cent-an-hour clickworker in Bogotá and the nine-figure Pentagon contract aren’t two separate stories. They’re two ends of the same cable.

## **Phase Three: Activating the Narrative Circuit**

On January 3rd, 2026, the Fatherboard went fully operational.

Around 1 a.m. Eastern, U.S. special operations forces launched a raid on Nicolás Maduro’s compound in Caracas with over 150 aircraft. Venezuela’s air defenses went silent before they could fire a single shot, taken offline through cyber operations and electronic warfare that spoofed radars and severed command links.

Then the narrative circuit exploded. Trump posted an announcement on social media: Maduro captured, America victorious, with no images or video attached. Within hours, the timelines filled with photos of Maduro being frog-marched down corridors by men in tactical gear, shots from multiple angles. The mayor of Coral Gables shared one, influencers amplified others. When researchers ran these frames through Google’s own AI detection tools, they flagged as Gemini-generated, complete with wrong star counts on flags and inconsistent uniform badges.

Then came the video: massive crowds of Venezuelans supposedly in the streets, sobbing with gratitude, some kneeling in thanks to Trump. Posted by Wall Street Apes, boosted by Elon Musk to his 200 million followers, the video spread like wildfire. Only later did fact-checkers trace it back to a TikTok account specializing in AI-generated spectacle, revealing wrong flags, repeating faces, and objects that popped in and out of existence.

By the time anyone said “this is fake,” 5.6 million people had watched it.

Now here’s where it gets really interesting. That same evening, while these AI-generated images and videos are still ripping through social media, Elon Musk sits down to dinner at Mar-a-Lago with Trump and Melania. He changes his profile picture on X to an American flag and posts: “Congratulations, President Trump! This is a win for the world and a clear message to evil dictators everywhere.”

And if you’re still holding onto some fantasy that Elon Musk and Donald Trump were ever locked in some kind of adversarial relationship, that they’re fighting for control or influence, let me be very clear: they’re not. They never were. This isn’t about personal loyalty or friendship. It’s about infrastructure and perfectly aligned interests.

Think about what Musk actually controls. His Starlink satellites are carrying military communications traffic. His AI models are being integrated into GenAI.mil, the Pentagon’s new AI warfare system. And his social media platform, X, is the distribution mechanism for all that synthetic war footage that just shaped what hundreds of millions of people believe happened in Caracas. He doesn’t need to sit behind the Resolute Desk in the Oval Office to be part of the government. He’s already embedded in the operating system itself, and that position is far more powerful than any cabinet seat could ever be.

Now watch what happens next, because the timing here is crucial. Only after these AI-generated fakes have completely dominated the information environment for a full day does the White House finally release what it calls “official” content. A short perp walk video showing Maduro being escorted down a hallway. A still photograph of him on the deck of the USS Iwo Jima. But here’s what fascinated me: the aesthetic of these official releases rhymes almost perfectly with the earlier AI-generated images. Same dim institutional interiors. Same flanking escorts. Same cinematic mid-chest camera height that makes everything look like a scene from a prestige television drama.

Do you see what they’re doing? First the synthetic imagery floods the zone and dominates the conversation. Then the official version drops into that same visual register, that same aesthetic language. By the time the “real” content arrives, fact itself has already started to feel slippery and unreliable. Once you can’t easily distinguish between what’s real and what’s fake, once that distinction starts to feel impossible to determine, you eventually just stop trying. And that surrender, that exhausted shrug of “whatever, who even knows what’s true anymore,” that’s the entire point. That’s AI’s strongest weapon.

## **The Beta Test**

Now if you think what happened on January 3rd just appeared out of nowhere, you haven’t been paying attention. The Fatherboard didn’t materialize overnight. Venezuela has been the testing ground for all of this for years, the place where they worked out the bugs and refined the techniques before the full deployment.

Let me show you what I mean. Back in early 2023, Venezuelan state media rolled out something that seemed almost laughably dystopian at first: AI-generated news anchors named Noah and Daren. They were created using a platform called Synthesia, and they looked like any bland cable news presenter you’ve ever half-watched while scrolling your phone. Smooth, unblinking delivery reading propaganda scripts on government-aligned channels. It took journalists and fact-checkers weeks of investigation to expose what was actually happening, but by that point these synthetic anchors had already been on the air, shaping the narrative, for quite some time.

But the real infrastructure of control goes much deeper. The Venezuelan government has been expanding something called the Carnet de la Patria, which translates to the Fatherland Card. It’s a biometric ID and benefits system, and here’s how it works: the system was built with assistance from Chinese tech giant ZTE, and it links people’s access to the most basic necessities of life, things like food subsidies, fuel rations, and cash bonuses, directly to their political loyalty and participation in pro-regime activities.

[![](https://substackcdn.com/image/fetch/$s_!m3rf!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ae9b901-5bb5-4de7-9061-bb590aea3339_250x157.jpeg)](https://substackcdn.com/image/fetch/$s_!m3rf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ae9b901-5bb5-4de7-9061-bb590aea3339_250x157.jpeg)

There’s also an app that comes with the Fatherland Card system, and this app does something particularly insidious. It invites citizens to report on “what they see, what they hear,” effectively turning the entire population into a potential surveillance network. Your neighbors, your coworkers, people you pass on the street, all of them potential informants feeding data into the system. And it’s not theoretical. Security forces at checkpoints have been documented demanding that people unlock their phones so they can scroll through private messages and photos. One man was jailed over a WhatsApp post where he complained about gas shortages. Another was detained for sharing a meme that showed U.S. military assets positioned near Venezuela’s coastline.

Meanwhile, researchers at an organization called the Digital Democracy Institute of the Americas spent months meticulously tracking regime-aligned social media campaigns. What they found should terrify you: in key propaganda pushes, roughly 96.5 percent of the posts were coming from coordinated inauthentic accounts or outright bots. Think about that number for a second. In one campaign they analyzed, a single hashtag generated 1.35 million messages. But when they dug into the data, they found those messages came from just over 15,000 user accounts, and those accounts were being amplified by nearly 6,000 additional bot accounts. The real human voices, the people trying to talk about what was actually happening in their lives, were completely drowned out by synthetic noise.

Jeanfreddy Gutiérrez, a Venezuelan fact-checker who has been documenting these operations for years, put it simply: “People were conditioned to disbelieve everything.”

And here’s the sickest part of all this, the thing that should make you feel physically ill: The tools that created this information desert, the systems that make it impossible to know what’s real, were trained in significant part by the very people who are now trapped inside that desert. Venezuelan ghost workers, sitting in cramped apartments in Bogotá and Medellín, labeled the images and sorted the text that went into commercial AI systems. Those systems then fed back into both the state surveillance infrastructure inside Venezuela and into U.S. military and propaganda operations. The desperation that was created by sanctions became the fuel for the machine, and now that machine is running at full speed, chewing through reality itself.

The machine ate them first. You’re next in line.

## **The Blueprint**

Two months before the raid, the Center for Strategic and International Studies published “How to Win the Information Game in Venezuela,” written by a senior fellow who also works as an executive at FilterLabs, which sells AI-driven sentiment analysis tools. The paper describes using “agentic AI” to monitor localized sentiment, detect emotional windows opened by tragedy or scandal, and auto-generate tailored propaganda messages in local dialect designed to exploit those openings. “With how unpopular President Maduro is,” the author concludes, “finding opportunities to safely deploy messaging won’t be hard.”

They wrote the doctrine, then ran the operation two months later in the same country. In many ways you’re not reading news; you’re reading the lab notes after they finished the experiment on you.

Zoom out and of course, Gaza appears in the frame. Because systems like Lavender and The Gospel (which I have covered in previous pieces) have been automating target selection with ten percent error rates and human operators rubber-stamping recommendations in twenty seconds. Gaza was the slow burn, Venezuela the accelerated version, proving the formula works at high speed.

## **The Complete System**

The Fatherboard has three interlocking circuits. The physical circuit uses satellites, cloud platforms, cyber units, and networked weapons to delete defenses before anyone knows they’re under attack. The human circuit exploits underpaid annotators from collapsing economies to train the models powering everything else. The narrative circuit deploys bots, synthetic media, and algorithmic messaging to make it impossible to reconstruct what actually happened.

Venezuela is where all three came online simultaneously, proving you can blind an air defense grid, fly a head of state out of his capital, use the labor of people you helped impoverish to build the tools that made it possible, and surround the event with enough synthetic content that the world argues not about whether it was right, but about what even occurred.

The Fatherboard runs on your passivity, your exhaustion, your belief that you’re too small to matter. That’s part of the design.

But there are vulnerable points. Congress could treat AI as arms control, requiring watermarking for synthetic media, public reporting on military AI use, and real oversight of contractor labor practices. Platforms could be forced to choose: if you profit from algorithmic amplification, you’re responsible for what you amplify, including AI-generated war footage when you have detection tools that could flag it.

And we have to stop pretending we’re outside this. Every CAPTCHA solved, every post flagged, every “help us improve” box checked is fuel. We’re doing free QA for systems designed to make us uncertain about reality itself. That doesn’t mean log off forever, but it means treating every emotionally charged image like a potential weapon, asking who benefits before retweeting, and understanding that refusal is resistance.

We collapsed Venezuela’s economy, harvested its workers at pennies an hour, wired their labor into military and social media systems, invaded the country whose people helped build those systems, then made it impossible for anyone to know what was true about that invasion.

Oskarina Fuentes spent years teaching algorithms how to see. Now those systems generate fake images of her country’s humiliation that circle the globe before breakfast. She helped build the tools that make it impossible for her, or you, to know what’s real when you look at Venezuela.

That word, *deleted*, was never about missile batteries. What’s being deleted is the floor itself, the minimum agreement about what counts as reality, the assumption that footage can be verified and facts are knowable. That floor is being pulled out in real time, and most people haven’t noticed it’s gone.

The Fatherboard is running right now, built on Venezuelan backs and aimed at yours. They’re betting you’ll feel small, overwhelmed, and tired, that you’ll doomscroll and shrug and move on.

Get angry instead. At the contracts that turned desperation into training data. At the sanctions that created that desperation. At the platforms and ministries that saw a collapsing country and recognized a discount labor pool and test range. Aim that anger upward, at the systems and people running them.

---

### **A Note on Resources:**

I know this kind of writing is heavy, and I don’t want to leave you sitting in a puddle of existential dread without any tools to fight back. So I’ve put together a list of resources that I genuinely use when I’m trying to figure out if something I’m looking at is real or AI-generated. Some of these are tools you can use to check images and videos. Others are really great breakdowns and guides that will teach you how to start seeing the tells yourself, because we can’t just rely on tools to do this work for us. We need to train our own eyes and develop our own instincts.

None of these resources are perfect. The technology is evolving faster than the detection methods, and that’s by design. But this is a good place to start. I want to teach you to fish, not just hand you a fish. The more people who know how to spot this stuff, the harder it becomes for them to get away with it.

1. Reporter’s Guide to Detecting AI-Generated Content (Global Investigative Journalism Network) – How newsrooms spot fakes, from visual tells to forensic tools.​ <https://gijn.org/resource/guide-detecting-ai-generated-content/>
2. InVID-WeVerify browser plugin (Bellingcat) – Free extension that freezes video, reverse-searches images, extracts metadata, and flags deepfakes. Install it now.​ <https://bellingcat.gitbook.io/toolkit/more/all-tools/invid>
3. Bellingcat’s Beginner’s Guide to Social Media Verification – Think like an investigator: Who posted this? When? Where? Has it been recycled?​ <https://www.bellingcat.com/resources/2021/11/01/a-beginners-guide-to-social-media-verification/>
4. Bellingcat’s Advanced Guide to Verifying Video Content – Slice videos into frames, reverse-search them, check shadows and geography. The playbook for catching reused footage.​ <https://www.bellingcat.com/resources/how-tos/2017/06/30/advanced-guide-verifying-video-content/>
5. TrueMedia.org – Upload an image, run it through multiple AI-detection models, get a score. Not perfect, but it’s a signal.​

   <https://www.truemedia.org/>
6. AI-generated images are everywhere. Here’s how to spot them (NPR) – The SIFT model: Stop, Investigate the source, Find better coverage, Trace back.​ <https://www.npr.org/2023/06/07/1180768459/how-to-identify-ai-generated-deepfake-images>

---

## SOURCES CITED:

* **MIT Technology Review – “Desperate Venezuelans are making money by training AI for self‑driving cars”** (Aug 22, 2019)  
  <https://www.technologyreview.com/2019/08/22/65375/venezuela-crisis-platform-work-trains-self-driving-car-ai-data/>

* **MIT Technology Review – “How the AI industry profits from catastrophe”** (Apr 20, 2022)

  <https://www.technologyreview.com/2022/04/20/1050392/ai-industry-appen-scale-data-labels/>​
* **El País – “The Venezuelan ghost workers who are feeding artificial intelligence”** (Jun 7, 2023)  
  <https://english.elpais.com/international/2023-06-07/the-venezuelan-ghost-workers-who-are-feeding-artificial-intelligence.html>​
* **New York Times – “A Timeline of Rising Tension Between the U.S. and Venezuela”** (Jan 3, 2026)  
  <https://www.nytimes.com/2026/01/03/world/americas/us-venezuela-tensions-timeline.html>
* **CNN Politics – “A timeline of US strikes on boats that have killed 115”** (Nov 2, 2025)  
  <https://www.cnn.com/2025/11/02/politics/timeline-us-strikes-caribbean-pacific-vis>​
* **Defense News – “Pentagon taps four commercial tech firms to expand military use of AI”** (Jul 15, 2025)

  <https://www.defensenews.com/pentagon/2025/07/15/pentagon-taps-four-commercial-tech-firms-to-expand-military-use-of-ai/>
* **DefenseScoop – “NATO inks deal with Palantir for Maven AI system”** (Apr 14, 2025)  
  <https://defensescoop.com/2025/04/14/nato-palantir-maven-smart-system-contract/>​
* **New Technology, Work and Employment (Wiley) – “Data enrichment and the hidden human labour of AI”** (2023)

  <https://onlinelibrary.wiley.com/doi/full/10.1111/ntwe.12340>
* **The World – “Venezuelans fear ‘Fatherland Card’ may be a new form of social control”** (Dec 27, 2018)  
  <https://theworld.org/stories/2018/12/27/venezuelans-shudder-news-biometric-id-deal-chinese-tech-giant>​
* **El País – “They’re not TV anchors, they’re avatars: How Venezuela is using AI-generated propaganda”** (Feb 22, 2023)  
  <https://english.elpais.com/international/2023-02-22/theyre-not-tv-anchors-theyre-avatars-how-venezuela-is-using-ai-generated-propaganda.html>​
* **Business & Human Rights Resource Centre – “Venezuelan migrants paid incredibly low wages to train generative AI algorithms”**

  <https://www.business-humanrights.org/en/latest-news/venezuelan-migrants-paid-incredibly-low-wages-to-train-generative-ai-algorithms/>​
* **INET Economics – “Venezuela: The Hidden Workforce Behind Oil, AI, and a Fragile Nation”**

  <https://www.ineteconomics.org/perspectives/blog/venezuela-the-hidden-workforce-behind-oil-ai-and-a-fragile-nation>
* **New York Times – “A.I. Images of Maduro Spread Rapidly, Despite Safeguards”** (Jan 5, 2026)

  <https://www.nytimes.com/2026/01/05/technology/nicolas-maduro-ai-images-deepfakes.html>​
* D**ata Big and Small – “American AI, Made in Venezuela”** (Jan 3, 2026)

  <https://databigandsmall.com/2026/01/03/american-ai-made-in-venezuela/>
* **CEPA – “Sino-Russian Convergence in Foreign Information Manipulation and Interference”** (2024)

  <https://cepa.org/comprehensive-reports/sino-russian-convergence-in-foreign-information-manipulation-and-interference/>
* **CSIS – “How to Win the Information Game in Venezuela”** (Nov 16, 2025)

  <https://www.csis.org/analysis/how-win-information-game-venezuela>

---

**Title:** The Fatherboard: Venezuela & AI Warfare
**Publication:** The Drey Dossier
**Date:** Fri, 09 Jan 2026 18:08:53 GMT
**Link:** https://thedreydossier.substack.com/p/the-fatherboard-venezuela-and-ai
